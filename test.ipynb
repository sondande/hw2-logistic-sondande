{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analytics and visualization for logistics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      "File: occupancy.csv\n",
      "Learning rate: 0.01\n",
      "Training Set Percent: 0.6\n",
      "Validation Set Percent: 0.2\n",
      "Testing Set Percent: 0.2\n",
      "Random Seed: 12345\n",
      "\n",
      "Number of Instances in Dataframe: 20560\n",
      "Splits indexes they begin at: [12336, 16448]\n",
      "\n",
      "Length of training: 12336\n",
      "Length of validiation set: 4112\n",
      "Length of testing: 4112\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Get Dataset File\n",
    "    # a.The path to a file containing a data set (e.g., monks1.csv)\n",
    "    file_path = \"occupancy.csv\"\n",
    "\n",
    "    # b. The learning rate 𝜂 to use during stochastic gradient descent\n",
    "    learning_rate = float(\"0.01\")\n",
    "\n",
    "    #c. The percentage of instances to use for a training set\n",
    "    training_set_percent = float(\"0.6\")\n",
    "    # Ensure training set percent is a valid percent that can be used\n",
    "    if 0 > training_set_percent or training_set_percent > 1:\n",
    "        print(\"Invalid percent. Please choose a value between 0 and 1\")\n",
    "        exit(1)\n",
    "\n",
    "    #d. The percentage of instances to use for a validation set\n",
    "    validation_set_percent = float(\"0.2\")\n",
    "\n",
    "    # Ensure validation set percent is a valid percent that can be used\n",
    "    if 0 > validation_set_percent or validation_set_percent > 1:\n",
    "        print(\"Invalid percent. Please choose a value between 0 and 1\")\n",
    "        exit(1)\n",
    "\n",
    "    # Check that the values don't exceed 100%\n",
    "    if training_set_percent + validation_set_percent == 1:\n",
    "        print(\"Fair warning ... you don't have a testing set...\\nPlease try again and leave room for a testing set :)\")\n",
    "        exit(1)\n",
    "    elif training_set_percent + validation_set_percent > 1:\n",
    "        print(f\"The percentage of the training set plus the validation set is equal to: {training_set_percent + validation_set_percent}\\nPlease only input values who's sum is less than 1\")\n",
    "        exit(1)\n",
    "\n",
    "    # Store the size of the testing set\n",
    "    testing_set_percent = 1 - training_set_percent - validation_set_percent\n",
    "\n",
    "    #e. A random seed as an integer\n",
    "    randomSeed = int(\"12345\")\n",
    "\n",
    "    # Print all input values given for user to see\n",
    "    print(f\"Inputs:\\nFile: {file_path}\\nLearning rate: {learning_rate}\")\n",
    "    print(f\"Training Set Percent: {training_set_percent}\\nValidation Set Percent: {validation_set_percent}\\nTesting Set Percent: {testing_set_percent}\")\n",
    "    print(f\"Random Seed: {randomSeed}\\n\")\n",
    "\n",
    "    # Read in dataset\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # shuffle the dataframe. Use random seed from input and fraction 1 as we want the whole dataframe\n",
    "    shuffled_df = df.sample(frac=1,random_state=randomSeed)\n",
    "\n",
    "    print(f\"Number of Instances in Dataframe: {len(df)}\")\n",
    "\n",
    "    # Applies the splits to the training set and validation set. The last argument wil what remained whihc is the testing set\n",
    "    # Note, Numpy split does it where there are equal parts. First one says take the first <test_set_percent> amount of my dataframe\n",
    "    # Second says, Take <training_set_percent + validation_set_percent> as training_set_percent is already taken so that leaves just the validation set amount\n",
    "    # These points go by indices so that index of where to start the validation set is the sum of the two. The remaining amount is the left over argument that is the part of the dataframe not taken.\n",
    "    # This results in that being the testing set\n",
    "    splits_indices = [int(training_set_percent * len(df)), int((training_set_percent + validation_set_percent) * len(df))]\n",
    "    print(f\"Splits indexes they begin at: {splits_indices}\\n\")\n",
    "    training_set, validation_set, testing_set = np.split(shuffled_df, splits_indices)\n",
    "\n",
    "    print(f\"Length of training: {len(training_set)}\")\n",
    "    print(f\"Length of validiation set: {len(validation_set)}\")\n",
    "    print(f\"Length of testing: {len(testing_set)}\")\n",
    "\n",
    "    # 1. Choose random values for all weights (often between -0.1 and 0.1)\n",
    "    weights = np.random.uniform(-0.1, 0.1, training_set.shape[1])\n",
    "\n",
    "except IndexError as e:\n",
    "    print(f\"Error. Message below:\\n{e}\\nPlease try again.\")\n",
    "    exit(1)\n",
    "except ValueError as e:\n",
    "    print(f\"Error. Message below:\\n{e}\\nPlease try again.\")\n",
    "    exit(1)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error. Message below:\\n{e}\\nPlease try again.\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process to encode nominal columns or calculate the values for \n",
    "new_dataframe = pd.DataFrame()\n",
    "for x in training_set.columns:\n",
    "    # For Nominial Value\n",
    "    if is_string_dtype(training_set[x]) and not is_numeric_dtype(training_set[x]):\n",
    "        new_dataframe = pd.concat([new_dataframe, pd.get_dummies(training_set[x], prefix=x, prefix_sep='.')],axis=1)\n",
    "        # training_set.drop([x],axis=1, inplace=True)\n",
    "    else: \n",
    "        max_value = max(training_set[x])\n",
    "        min_value = min(training_set[x])\n",
    "        if max_value != 0 and min_value != 0:\n",
    "            training_set[x] = training_set[x].apply(lambda x: (x - min_value)/(max_value - min_value))\n",
    "        new_dataframe = pd.concat([new_dataframe, training_set[x]],axis=1)\n",
    "        # training_set.drop([x],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_calculate(weights, x_instance):\n",
    "    # take the first value from weights as it is part of the net without a corresponding value in the instance\n",
    "    net = weights[0]\n",
    "    # Instances and weights are the same length\n",
    "    for i in range(1, len(weights)):\n",
    "        net += weights[i] * x_instance[i]\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(net):\n",
    "    # If x is a very large positive number, the sigmoid function will be close to 1\n",
    "    if net >= 0:\n",
    "        z = np.exp(-net)\n",
    "        return 1 / (1 + z)\n",
    "    # If x is a very large negative number, the sigmoid function will be close to 0\n",
    "    else:\n",
    "        z = np.exp(net)\n",
    "        return z / (1 + z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net: -3.8905961879875623\n",
      "Out: 0.020024006661076822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_ts = training_set.to_numpy()\n",
    "net = net_calculate(weights=weights, x_instance=np_ts[0])\n",
    "out = sigmoid(net=net)\n",
    "print(f\"Net: {net}\\nOut: {out}\")\n",
    "len(np_ts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(training_set, validation_set, learning_rate):\n",
    "    np_ts = training_set.to_numpy()\n",
    "    np_vs = validation_set.to_numpy()\n",
    "    # 1. Choose random values for all weights (often between -0.1 and 0.1)\n",
    "    weights = np.random.uniform(-0.1, 0.1, training_set.shape[1])\n",
    "    # 2. Unitl either the accuracy on the validation set > A% or we run n epochs\n",
    "    # Set accuracy variable \n",
    "    accuracy = 0\n",
    "    epochs = 0\n",
    "    while accuracy <= 0.99 and epochs < 500:\n",
    "        # A. For each instance x in the training set\n",
    "        for insta_count in range(len(np_ts)):\n",
    "            # Calculate Net Value between X instance and weights\n",
    "            net = net_calculate(weights=weights, x_instance=np_ts[insta_count])\n",
    "            # Calculate the out values from the net values calculated above \n",
    "            out_value = sigmoid(net=net)\n",
    "            # I. Calculate gradient of w0\n",
    "            grad_w0 = -1 * out_value * (1 - out_value) * (np_ts[insta_count][0] - out_value)\n",
    "            # Update first weight in weights\n",
    "            weights[0] -= learning_rate * grad_w0\n",
    "            # II. Calculate gradient of wi\n",
    "            for attr_count in range(1, len(np_ts[0])):\n",
    "                grad_wi = -np_ts[insta_count][attr_count] * out_value * (1 - out_value) * (np_ts[insta_count][0] - out_value)\n",
    "                weights[attr_count] -= learning_rate * grad_wi\n",
    "            # print(f\"Updated weights list: {weights}\\n\")\n",
    "        epochs += 1\n",
    "        tt = 0\n",
    "        tf = 0 \n",
    "        ft = 0\n",
    "        ff = 0\n",
    "        # Testing against validation set\n",
    "        for insta_count in range(len(np_vs)):\n",
    "            # Calculate Net Value between X instance and weights\n",
    "            net = net_calculate(weights=weights, x_instance=np_vs[insta_count])\n",
    "            # Calculate the out values from the net values calculated above \n",
    "            out_value = sigmoid(net=net)\n",
    "            predict = 1 if out_value > 0.5 else 0\n",
    "            # print(f\"Predict Value:{predict}\")\n",
    "            if predict == 1  and np_vs[insta_count][0] == 1:\n",
    "                tt += 1 \n",
    "            elif predict == 1  and np_vs[insta_count][0] == 0:\n",
    "                tf += 1 \n",
    "            elif predict == 0  and np_vs[insta_count][0] == 1:\n",
    "                ft += 1 \n",
    "            else: \n",
    "                ff += 1\n",
    "        accuracy = (tt + ff) / (tt + tf+ ft+ ff)\n",
    "        print(f\"Completed Epoch:{epochs}\\nAccuracy: {accuracy}\\nWeights: {weights}\\n\")\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stochastic_gradient_descent(training_set=training_set, validation_set=validation_set, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "np_ts[0:][1:]\n",
    "np_ts[0:][:1]\n",
    "labels = training_set.iloc[:, :1].to_numpy()\n",
    "clf = LogisticRegression(random_state=0).fit(training_set.iloc[:, 1:], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(training_set.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9875162127107653"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(training_set.iloc[:, 1:], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>HumidityRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20552</th>\n",
       "      <td>1</td>\n",
       "      <td>0.330971</td>\n",
       "      <td>0.451989</td>\n",
       "      <td>419.0</td>\n",
       "      <td>0.646281</td>\n",
       "      <td>0.375955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3528</th>\n",
       "      <td>0</td>\n",
       "      <td>0.146071</td>\n",
       "      <td>0.111844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017280</td>\n",
       "      <td>0.017882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3510</th>\n",
       "      <td>0</td>\n",
       "      <td>0.146071</td>\n",
       "      <td>0.111844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017581</td>\n",
       "      <td>0.017882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>0</td>\n",
       "      <td>0.406780</td>\n",
       "      <td>0.116238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047032</td>\n",
       "      <td>0.088239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20405</th>\n",
       "      <td>0</td>\n",
       "      <td>0.330971</td>\n",
       "      <td>0.437486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.637566</td>\n",
       "      <td>0.362644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  Temperature  Humidity  Light       CO2  HumidityRatio\n",
       "20552      1     0.330971  0.451989  419.0  0.646281       0.375955\n",
       "3528       0     0.146071  0.111844    0.0  0.017280       0.017882\n",
       "3510       0     0.146071  0.111844    0.0  0.017581       0.017882\n",
       "1578       0     0.406780  0.116238    0.0  0.047032       0.088239\n",
       "20405      0     0.330971  0.437486    0.0  0.637566       0.362644"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20552</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3528</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3510</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20405</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11266</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11645</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7408</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4791</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19081</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12336 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label\n",
       "20552      1\n",
       "3528       0\n",
       "3510       0\n",
       "1578       0\n",
       "20405      0\n",
       "...      ...\n",
       "11266      0\n",
       "11645      0\n",
       "7408       0\n",
       "4791       0\n",
       "19081      1\n",
       "\n",
       "[12336 rows x 1 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.iloc[:, :1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
